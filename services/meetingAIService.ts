/**
 * Servi√ßo para processamento de reuni√µes com IA
 * Handles transcri√ß√£o de √°udio e gera√ß√£o de atas estrat√©gicas
 */

// Interface para resposta da IA
interface AIResponse {
  transcription: string;
  meetingMinutes: string;
  success: boolean;
  error?: string;
}

// Template da ata conforme especificado
const STRATEGIC_MEETING_TEMPLATE = `## üéØ 1. Auditoria do Prop√≥sito
* **Motiva√ß√£o Original:** {motivation}
* **Veredito de Efici√™ncia:** {efficiency_verdict}

## üìù 2. Pauta Retroativa (O que foi discutido)
{agenda_items}

## üîë 3. Decis√µes e Insights Chave
{key_decisions}

## üöÄ 4. Plano de A√ß√£o (Next Steps)
| Tarefa | Respons√°vel | Prioridade |
| :--- | :--- | :--- |
{action_items}

## ‚ö†Ô∏è 5. Pontos de Aten√ß√£o / Bloqueios
{attention_points}

---
**Transcri√ß√£o da Reuni√£o:**
{full_transcription}`;

/**
 * Processa √°udio e gera ata estrat√©gica usando IA
 */
export class MeetingAIService {
  private static instance: MeetingAIService;
  
  // URLs dos servi√ßos (configurar conforme ambiente)
  private readonly TRANSCRIPTION_API = '/api/transcribe'; // Whisper/Gemini
  private readonly AI_ANALYSIS_API = '/api/analyze-meeting'; // GPT-4/Gemini

  static getInstance(): MeetingAIService {
    if (!MeetingAIService.instance) {
      MeetingAIService.instance = new MeetingAIService();
    }
    return MeetingAIService.instance;
  }

  /**
   * Processa √°udio da reuni√£o e gera ata completa
   */
  async processAudioMeeting(
    audioBlob: Blob, 
    meetingTitle: string, 
    participants: string[]
  ): Promise<AIResponse> {
    try {
      // 1. Transcrever √°udio
      console.log('üé§ Iniciando transcri√ß√£o do √°udio...');
      const transcription = await this.transcribeAudio(audioBlob);
      
      if (!transcription) {
        throw new Error('Falha na transcri√ß√£o do √°udio');
      }

      // 2. Analisar transcri√ß√£o e gerar ata estrat√©gica
      console.log('üß† Analisando transcri√ß√£o e gerando ata...');
      const meetingMinutes = await this.generateStrategicMinutes(
        transcription, 
        meetingTitle, 
        participants
      );

      return {
        transcription,
        meetingMinutes,
        success: true
      };

    } catch (error) {
      console.error('Erro no processamento da reuni√£o:', error);
      return {
        transcription: '',
        meetingMinutes: this.getFallbackMinutes(meetingTitle, participants),
        success: false,
        error: error instanceof Error ? error.message : 'Erro desconhecido'
      };
    }
  }

  /**
   * Transcreve √°udio usando Whisper/Gemini API
   */
  private async transcribeAudio(audioBlob: Blob): Promise<string> {
    // Preparar FormData para upload
    const formData = new FormData();
    formData.append('audio', audioBlob, 'meeting.wav');
    formData.append('language', 'pt-BR');
    formData.append('model', 'whisper-1');

    try {
      // Op√ß√£o 1: Whisper API (OpenAI)
      if (this.hasOpenAIKey()) {
        return await this.transcribeWithWhisper(formData);
      }
      
      // Op√ß√£o 2: Gemini API (Google)
      if (this.hasGeminiKey()) {
        return await this.transcribeWithGemini(audioBlob);
      }

      // Op√ß√£o 3: API local/customizada
      return await this.transcribeWithLocalAPI(formData);

    } catch (error) {
      console.error('Erro na transcri√ß√£o:', error);
      return 'Transcri√ß√£o n√£o dispon√≠vel - erro no processamento do √°udio.';
    }
  }

  /**
   * Transcri√ß√£o usando Whisper (OpenAI)
   */
  private async transcribeWithWhisper(formData: FormData): Promise<string> {
    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: formData
    });

    if (!response.ok) {
      throw new Error(`Whisper API error: ${response.status}`);
    }

    const data = await response.json();
    return data.text || '';
  }

  /**
   * Transcri√ß√£o usando Gemini (Google)
   */
  private async transcribeWithGemini(audioBlob: Blob): Promise<string> {
    // Converter para base64 para Gemini
    const base64Audio = await this.blobToBase64(audioBlob);
    
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${process.env.GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: "Transcreva este √°udio em portugu√™s brasileiro. Retorne apenas o texto transcrito:"
          }, {
            inline_data: {
              mime_type: "audio/wav",
              data: base64Audio
            }
          }]
        }]
      })
    });

    if (!response.ok) {
      throw new Error(`Gemini API error: ${response.status}`);
    }

    const data = await response.json();
    return data.candidates?.[0]?.content?.parts?.[0]?.text || '';
  }

  /**
   * Transcri√ß√£o via API local
   */
  private async transcribeWithLocalAPI(formData: FormData): Promise<string> {
    const response = await fetch(this.TRANSCRIPTION_API, {
      method: 'POST',
      body: formData
    });

    if (!response.ok) {
      throw new Error(`Local transcription API error: ${response.status}`);
    }

    const data = await response.json();
    return data.transcription || '';
  }

  /**
   * Gera ata estrat√©gica usando o framework especificado
   */
  private async generateStrategicMinutes(
    transcription: string,
    meetingTitle: string,
    participants: string[]
  ): Promise<string> {
    const analysisPrompt = `
# CONTEXTO E PERSONA
Voc√™ √© um Gerente de Projetos S√™nior e Analista de Neg√≥cios especialista em efici√™ncia corporativa. Sua tarefa √© analisar a transcri√ß√£o de uma reuni√£o gravada fornecida abaixo.

# OBJETIVO PRINCIPAL
Transformar o texto bruto da conversa em um documento estrat√©gico. N√£o quero apenas um resumo; quero entender a "alma" da reuni√£o: por que ela aconteceu, o que foi decidido e se ela foi √∫til.

# INSTRU√á√ïES DE AN√ÅLISE (O "FRAMEWORK")
Analise o texto buscando responder explicitamente a estes 4 pilares:
1. O PROP√ìSITO (O "Porqu√™"): Qual foi a dor, problema ou oportunidade que motivou esse encontro?
2. O CONTE√öDO (O "O que"): Quais t√≥picos foram debatidos para endere√ßar o prop√≥sito?
3. O RESULTADO (A "Conclus√£o"): O prop√≥sito foi atingido? Chegaram a um consenso?
4. A A√á√ÉO (O "E agora?"): Quem faz o que e quando?

# DADOS DA REUNI√ÉO
- **T√≠tulo:** ${meetingTitle}
- **Participantes:** ${participants.join(', ')}
- **Data:** ${new Date().toLocaleDateString('pt-BR')}

# TRANSCRI√á√ÉO
${transcription}

# FORMATO DE SA√çDA
Gere a resposta em Markdown seguindo exatamente esta estrutura:

## üéØ 1. Auditoria do Prop√≥sito
* **Motiva√ß√£o Original:** (Identifique o motivo expl√≠cito ou impl√≠cito da reuni√£o).
* **Veredito de Efici√™ncia:** (A reuni√£o cumpriu seu prop√≥sito? Responda: "Sim", "Parcialmente" ou "N√£o" e justifique em 1 frase).

## üìù 2. Pauta Retroativa (O que foi discutido)
(Liste os 3 a 5 principais t√≥picos discutidos, como se fosse a agenda da reuni√£o).
* T√≥pico A
* T√≥pico B

## üîë 3. Decis√µes e Insights Chave
(O que foi definido? O que aprendemos de novo? Use bullet points).

## üöÄ 4. Plano de A√ß√£o (Next Steps)
(Crie uma tabela com as colunas: "Tarefa", "Respons√°vel", "Prazo Estimado/Prioridade").
| Tarefa | Respons√°vel | Prioridade |
| :--- | :--- | :--- |
| [A√ß√£o] | [Nome] | [Alta/M√©dia/Baixa] |

## ‚ö†Ô∏è 5. Pontos de Aten√ß√£o / Bloqueios
(Algo ficou sem resposta? Houve conflito ou incerteza sobre algum ponto? Liste aqui).

---
**Transcri√ß√£o Completa:**
${transcription}`;

    try {
      // Usar Gemini/GPT para an√°lise
      if (this.hasGeminiKey()) {
        return await this.analyzeWithGemini(analysisPrompt);
      }
      
      if (this.hasOpenAIKey()) {
        return await this.analyzeWithOpenAI(analysisPrompt);
      }

      // Fallback para API local
      return await this.analyzeWithLocalAPI(analysisPrompt);

    } catch (error) {
      console.error('Erro na an√°lise da reuni√£o:', error);
      return this.getFallbackMinutes(meetingTitle, participants, transcription);
    }
  }

  /**
   * An√°lise usando Gemini
   */
  private async analyzeWithGemini(prompt: string): Promise<string> {
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${process.env.GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{ text: prompt }]
        }],
        generationConfig: {
          maxOutputTokens: 4000,
          temperature: 0.3
        }
      })
    });

    if (!response.ok) {
      throw new Error(`Gemini analysis error: ${response.status}`);
    }

    const data = await response.json();
    return data.candidates?.[0]?.content?.parts?.[0]?.text || '';
  }

  /**
   * An√°lise usando OpenAI GPT
   */
  private async analyzeWithOpenAI(prompt: string): Promise<string> {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: [
          { role: 'user', content: prompt }
        ],
        max_tokens: 4000,
        temperature: 0.3
      })
    });

    if (!response.ok) {
      throw new Error(`OpenAI analysis error: ${response.status}`);
    }

    const data = await response.json();
    return data.choices?.[0]?.message?.content || '';
  }

  /**
   * An√°lise via API local
   */
  private async analyzeWithLocalAPI(prompt: string): Promise<string> {
    const response = await fetch(this.AI_ANALYSIS_API, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ prompt })
    });

    if (!response.ok) {
      throw new Error(`Local AI analysis error: ${response.status}`);
    }

    const data = await response.json();
    return data.analysis || '';
  }

  /**
   * Ata de fallback caso a IA falhe
   */
  private getFallbackMinutes(
    meetingTitle: string, 
    participants: string[], 
    transcription?: string
  ): string {
    return `## üéØ 1. Auditoria do Prop√≥sito
* **Motiva√ß√£o Original:** ${meetingTitle}
* **Veredito de Efici√™ncia:** Processamento autom√°tico n√£o dispon√≠vel - revisar manualmente.

## üìù 2. Pauta Retroativa (O que foi discutido)
* Aguardando an√°lise manual da transcri√ß√£o
* Revisar √°udio ou transcri√ß√£o para identificar t√≥picos

## üîë 3. Decis√µes e Insights Chave
* Revisar manualmente a transcri√ß√£o para identificar decis√µes
* Completar esta se√ß√£o ap√≥s an√°lise

## üöÄ 4. Plano de A√ß√£o (Next Steps)
| Tarefa | Respons√°vel | Prioridade |
| :--- | :--- | :--- |
| Revisar e completar ata manualmente | A definir | Alta |

## ‚ö†Ô∏è 5. Pontos de Aten√ß√£o / Bloqueios
* Processamento autom√°tico indispon√≠vel
* Requer revis√£o manual da transcri√ß√£o

---
**Transcri√ß√£o da Reuni√£o:**
${transcription || 'Transcri√ß√£o n√£o dispon√≠vel - verifique o √°udio gravado.'}`;
  }

  /**
   * Helper: converte Blob para Base64
   */
  private async blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const base64 = (reader.result as string).split(',')[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  /**
   * Verifica se tem chave da OpenAI
   */
  private hasOpenAIKey(): boolean {
    return !!(process.env.OPENAI_API_KEY || (window as any).OPENAI_API_KEY);
  }

  /**
   * Verifica se tem chave do Gemini
   */
  private hasGeminiKey(): boolean {
    return !!(process.env.GEMINI_API_KEY || (window as any).GEMINI_API_KEY);
  }
}

// Inst√¢ncia singleton
export const meetingAIService = MeetingAIService.getInstance();